# Applied-Machine-Learning
Showcase - MS Business Analytics Coursework - UT Dallas 

I have used various algorithms to build models for Classification & Regression examples and projects.

Feature-Engine is used throughout the course for Pre-processing steps.

Below is the list of Algorithms/techniques used during my learnings:-

Basic Algorithms:-

1.	Logistic Regression
2.	Decision Tree
3.	k-Nearest Neighbors
4.	Support Vector Machine (optional as it may take long time to run)
5.	Random Forest
6.	Extra Trees
7.	Gradient Boosting
8.	XgBoost

Cost Sensitive Algorithms:- 
1.	Logistic Regression
2.	Decision Trees
3.	Support Vector Machines (optional as it may take long time to run)
4.	Random Forest
5.	XGBoost
6.	Extra Trees
7.	Bagging decision tree with under sampling


Data Sampling Algorithms:-
1.	Logistic Regression
2.	Decision Tree
3.	k-Nearest Neighbors
4.	Support Vector Machine (optional as it may take long time to run)
5.	Random Forest
6.	Easy Ensemble Classifier
7.	XgBoost
8.	Neural Network (scikit learn MLPClassifier)

Stacking Classifiers: Try to combine various models to create stacking models. Generally diverse models gives you better results. As a rule of thumb, you need one final estimator for every 7 base estimators. If you have more than 7 base estimators in your stack, then the final estimator should itself be a stacking model with more than one estimator. Combining models trained on  different data (one way to create different data set is using different pre-processing steps) can also sometimes gives better predictions. As a minimum you need to try at least three different combinations for stacking. 

Try at least three things which we have not covered in the class

Students should be able to learn new things and apply them. Here is the sample of things we have not covered in class :

1. Hyper parameter tuning methods other than GridSeachCV e.g. RandomSerachCV. 
2. Saving and Uploading models (pickle and/or Joblib)

Explore More Models/Libraries (some examples below)
1. Na√Øve Bayes
2. One Class Classification for imbalanced data (Isolation forest)
3. LDA 
4. QDA
5. GaussianProcessClassifier
6. CatBoost
7. Light GBM

